{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36115bee-fe73-48d7-9c33-9b11f95d1674",
   "metadata": {},
   "outputs": [],
   "source": [
    "import weaviate\n",
    "\n",
    "client = weaviate.connect_to_custom(\n",
    "    http_host=\"weaviate\",\n",
    "    http_port=\"8080\",\n",
    "    http_secure=False,\n",
    "    grpc_host=\"weaviate\",\n",
    "    grpc_port=\"50051\",\n",
    "    grpc_secure=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f60806d-560a-42ae-9475-3bd981bf0fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import weaviate.classes as wvc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fe77ebd-8130-47f7-ba05-865a788d88c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "docs = client.collections.get(\"Document\")\n",
    "response = docs.aggregate.over_all(total_count=True)\n",
    "\n",
    "print(response.total_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75ab920c-60e5-4891-84ba-d092b8636122",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def naive_rag(prompt, with_context=False):\n",
    "    if with_context:\n",
    "        r = docs.query.near_text(\n",
    "            query=prompt,\n",
    "            limit=1,\n",
    "        )\n",
    "        context = [o.properties['summary'] for o in r.objects]\n",
    "        context = '\\n'.join(context)\n",
    "        prompt = f\"Given the following context: {context}.\\nGenerate completion for the prompt: {prompt}\"\n",
    "        print(prompt)\n",
    "\n",
    "    payload = {\n",
    "        \"model\": \"llama-2\",\n",
    "        \"prompt\": prompt,\n",
    "        \"max_tokens\": 500,\n",
    "        \"temperature\": 0,\n",
    "        \"frequency_penalty\": 1.0\n",
    "    }\n",
    "    r = requests.post('http://vllm:8000/v1/completions', json=payload).json()\n",
    "    return r\n",
    "\n",
    "prompt = \"LLMs are\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "901390eb-a703-4071-b418-29859b3c01a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'cmpl-fc50aefaf38d4fd2adddf33578569ed3',\n",
       " 'object': 'text_completion',\n",
       " 'created': 159765,\n",
       " 'model': 'llama-2',\n",
       " 'choices': [{'index': 0,\n",
       "   'text': ' a great way to get your foot in the door of academia.\\nThe LLM is a master’s degree that is designed to prepare you for teaching at the graduate level. The program will give you the skills and knowledge needed to teach courses in law, business, or other fields.\\nLLM programs are offered by many universities around the country and can be completed in as little as one year or as long as three years. Some programs require students to complete an undergraduate degree first before applying for admission into their LLM program.\\nThe cost of an LLM varies depending on where you attend school and what type of program you choose. You can expect tuition costs between $15,000-$25,000 per year depending on your school’s location and whether it is online or campus-based. Most schools offer financial aid packages that include grants, loans, scholarships, work-study opportunities and more so that students can afford their education without having to take out student loans after graduation from college or university.\\nIf you are interested in pursuing an LLM but don’t have enough money saved up for tuition alone then consider taking out a loan through a private lender like SoFi who offers low interest rates with no fees attached!',\n",
       "   'logprobs': None,\n",
       "   'finish_reason': 'stop'}],\n",
       " 'usage': {'prompt_tokens': 5, 'total_tokens': 279, 'completion_tokens': 274}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_rag(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2afb899-5ecd-437e-b97b-46ace407bfb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given the following context: Large Language Models (LLMs) create exciting possibilities for powerful\n",
      "language processing tools to accelerate research in materials science. While\n",
      "LLMs have great potential to accelerate materials understanding and discovery,\n",
      "they currently fall short in being practical materials science tools. In this\n",
      "position paper, we show relevant failure cases of LLMs in materials science\n",
      "that reveal current limitations of LLMs related to comprehending and reasoning\n",
      "over complex, interconnected materials science knowledge. Given those\n",
      "shortcomings, we outline a framework for developing Materials Science LLMs\n",
      "(MatSci-LLMs) that are grounded in materials science knowledge and hypothesis\n",
      "generation followed by hypothesis testing. The path to attaining performant\n",
      "MatSci-LLMs rests in large part on building high-quality, multi-modal datasets\n",
      "sourced from scientific literature where various information extraction\n",
      "challenges persist. As such, we describe key materials science information\n",
      "extraction challenges which need to be overcome in order to build large-scale,\n",
      "multi-modal datasets that capture valuable materials science knowledge.\n",
      "Finally, we outline a roadmap for applying future MatSci-LLMs for real-world\n",
      "materials discovery via: 1. Automated Knowledge Base Generation; 2. Automated\n",
      "In-Silico Material Design; and 3. MatSci-LLM Integrated Self-Driving Materials\n",
      "Laboratories..\n",
      "Generate completion for the prompt: LLMs are\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': 'cmpl-3a613ebbfc6f4fc8b60c1b5cb9aa3a1a',\n",
       " 'object': 'text_completion',\n",
       " 'created': 159811,\n",
       " 'model': 'llama-2',\n",
       " 'choices': [{'index': 0,\n",
       "   'text': ' a powerful tool for materials\\nscience. However, they are currently limited in their ability to understand and\\nreason over complex materials science knowledge. In this position paper, we\\nshow that LLMs fall short in being practical materials science tools due to the\\nfollowing failure cases: 1. LLMs fail to comprehend and reason over complex,\\ninterconnected knowledge; 2. LLMs do not have sufficient data for hypothesis\\ngeneration; 3. LLMs lack multi-modal datasets sourced from scientific literature;\\n4. The current state of MatSci-LLM research is too early for practical use in a\\nmaterial discovery workflow.. We outline a framework for developing Materials Science LLM (MatSci-LLM) that is grounded in materials science knowledge and hypothesis generation followed by hypothesis testing.. We describe key information extraction challenges which need to be overcome in order to build large scale multi modal datasets that capture valuable material science knowledge.. Finally we outline a roadmap for applying future MatSci-LLMs for real world material discovery via: 1 Automated Knowledge Base Generation; 2 Automated In Silico Material Design; and 3 MatSci-LLM Integrated Self Driving Material Laboratories..',\n",
       "   'logprobs': None,\n",
       "   'finish_reason': 'stop'}],\n",
       " 'usage': {'prompt_tokens': 329,\n",
       "  'total_tokens': 596,\n",
       "  'completion_tokens': 267}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_rag(prompt, with_context=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57bbefa-1f43-42bd-96f3-ef43a74aae21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
